# Automatic-Essay-Grading-
Comprehensive instruction tuning, evaluation, and optimization of large language models (LLMs) for automated essay grading, using refined data analysis, preprocessing, and feature engineering. Conducted 39 experiments on models like Mistral, Qwen2.5, and SmolLM2 to assess their performance across real and synthetic datasets using both score and rationale evaluation.

# Abstraction
This work is a study of the performance of various models on an automated essay grading task, exploring what results Instruction Tuning can achieve on such a task, and which factors significantly affect performance compared to model-specific factors, such as the structure itself, size, and the amount of input tokens during learning. The results were promising, despite the relatively small data set and limited computational resources. However, you'll find that we used the most efficient optimization techniques, which allowed us to experiment and achieve the desired results.
